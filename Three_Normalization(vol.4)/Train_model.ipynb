{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras import layers, models\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Train_model:\n",
    "    def train_model(train_X, train_Y, classes_y, test_X, test_Y):\n",
    "        print('model training...')\n",
    "\n",
    "        print('MLP Classifier')\n",
    "        use_model = MLPClassifier(hidden_layer_sizes=(30, 10), max_iter=10, random_state=42)\n",
    "\n",
    "        mini_batch_size = 10000\n",
    "        batch_size = len(train_Y)\n",
    "        total_epoch = int(batch_size / mini_batch_size)\n",
    "        current_batch = 0\n",
    "\n",
    "        for i in range(1, total_epoch):\n",
    "            end_batch = i * mini_batch_size\n",
    "            use_model._partial_fit(train_X[current_batch:end_batch], train_Y[current_batch:end_batch], classes=classes_y)\n",
    "            current_batch = end_batch\n",
    "\n",
    "        use_model._partial_fit(train_X[current_batch:batch_size], train_Y[current_batch:batch_size], classes=classes_y)\n",
    "        use_model_score = cross_val_score(use_model, test_X, test_Y, scoring='accuracy', cv=10, n_jobs=8)\n",
    "        use_model_cross_val = cross_val_predict(use_model, test_X, test_Y, cv=10, n_jobs=8)\n",
    "        use_model_confusion_matrix = confusion_matrix(test_Y, use_model_cross_val)\n",
    "\n",
    "        return use_model_cross_val, use_model_score, use_model_confusion_matrix\n",
    "\n",
    "Nin = 49                # 입력 노드의 개수\n",
    "Nh_l = [100, 50]        # 히든 레이어 개수\n",
    "number_of_class = 15    # 분류 클래스 개수\n",
    "Nout = number_of_class  # 출력 노드의 개수\n",
    "\n",
    "class DNN(models.Sequential):\n",
    "\n",
    "    def __init__(self, Nin, Nh_l, Nout):\n",
    "        super().__init__()\n",
    "        self.add(layers.Dense(Nh_l[0], activation='relu', input_shape=(Nin,), name='Hidden-1'))\n",
    "        self.add(layers.Dense(Nh_l[1], activation='relu', name='Hidden-2'))\n",
    "        self.add(layers.Dense(Nout, activation='softmax'))\n",
    "        self.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    def dnn_model(train_X, train_Y, test_X, test_Y):\n",
    "        print('model training...')\n",
    "        print('DNN Classifier')\n",
    "\n",
    "        train_cnt_Y = Counter(train_Y)\n",
    "        test_cnt_Y = Counter(test_Y)\n",
    "        classes_y = len(train_cnt_Y.keys())\n",
    "        print('Attack Type Count : {}'.format(dict(train_cnt_Y)))\n",
    "\n",
    "        l_encoder = LabelEncoder()\n",
    "        train_Y = l_encoder.fit_transform(train_Y)\n",
    "        print(train_Y)\n",
    "\n",
    "\n",
    "        train_Y = to_categorical(train_Y, num_classes=15)\n",
    "        print(train_Y)\n",
    "        test_Y = to_categorical(test_Y, num_classes=15)\n",
    "        print(test_Y)\n",
    "\n",
    "        # train_Y = np_utils.to_categorical(train_Y, num_classes=15)\n",
    "        # test_Y = np_utils.to_categorical(test_Y, num_classes=15)\n",
    "\n",
    "        L, W, H = train_X.shape\n",
    "        print(L, W, H)\n",
    "        train_X = train_X.reshape(-1, )\n",
    "        test_X = test_X.reshape(-1, )\n",
    "\n",
    "        use_model = DNN(Nin, Nh_l, Nout)\n",
    "        history = use_model.fit(train_X, train_Y, epochs=100, batch_size=10000, validation_split=0.2)\n",
    "        performance_test = use_model.evaluate(test_X, test_Y, batch_size=10000)\n",
    "\n",
    "        return performance_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
